---
title: "P115-1 Analysis"
author: "James Eddy"
date: "July 31, 2015"
output: html_document
---

```{r global_opts}
knitr::opts_chunk$set(fig.width=8, fig.height=4, fig.align='center',
                      echo=FALSE, warning=FALSE, message=FALSE)
knitr::opts_knit$set(root.dir = "..")
```

### Set up R environment

#### Load packages

First, load required packages for data munging, visualization, and analysis
(these are largely Hadley Wickham libraries, plus some Bioconductor tools).

```{r load_packages}
# Load my go-to libraries
library(dplyr)
library(ggplot2)
library(cowplot)
library(stringr)
library(readr)
library(readxl)
library(reshape2)

# ..plus some others I'll need here
library(edgeR)
library(limma)
```

#### Set working directory

This is a small step that lets me switch between executing chunks interactively
and knitting the entire Rmd document without having to constantly modify file
paths. 

I need to test whether this does anything funky with how knitr saves files for
the final HTML document...

```{r source_functions}
source("R/metric_qc_functions.R")
```

#### Define functions

These are functions written by Elizabeth Whalen (shared by Michael Mason) that
might come in handy with some steps of the analysis. I might rewrite these at
some point to better match my own coding style and/or needs. I'll also likely
move most functions to an external R script, which I can just source here.

```{r whalen_functions}
# Some functions from Elizabeth that I might use...

# computes normalization from libraries and then filters genes by having % 
# samples with at least N counts and 
setUpDGEList <- function(countData, filterCount=1, filterPercentage=0.1)
{
	d <- DGEList(counts=countData)
	d <- calcNormFactors(d)

	keepRows <- rowSums(round(cpm(d$counts)) >= filterCount) >= filterPercentage*ncol(countData)
	print(table(keepRows))

	curDGE <- d[keepRows,]
	return(curDGE)
}
```

#### Load data

Next, load in counts and metrics data for the project, as well as sample
annotation for project libraries.
```{r load_data}
# Read CSV file with read counts
countFile <- "data/HMMF2ADXX_combined_counts_wMgiSymbol.csv"
countDat <- read_csv(countFile) # 37991 obs. of  18 variables
# str(countDat)

# Read CSV file with RNAseq/alignment metrics
metricFile <- "data/HMMF2ADXX_combined_metrics.csv"
metricDat <- read_csv(metricFile) # 16 obs. of  71 variables
# str(metricDat)

# Read XLSX file with sample annotation
designFile <- "data/JMD119 Sample Information .xlsx"
designDat <- read_excel(designFile, skip = 1) # 36 obs. of 18 variables
# str(designDat)
```


#### Clean data

I need to do a bit of cleaning/formatting with variable names (column headers)
to make life easier and avoid breaking downstream functions.
```{r clean_data}
gene <- countDat$mgiSymbol
countDat <- countDat %>% 
    select(-geneName, -mgiSymbol)
names(countDat) <- names(countDat) %>% 
    str_extract("lib[0-9]+")

# Reformat variable names in metrics data frame
names(metricDat) <- names(metricDat) %>% 
    str_to_lower() %>%  # change variable names to lower case
    make.unique(sep = "_") # de-dup variable names
names(metricDat)[1] <- "lib_id" # reformat libID variable name

# Reformat row names in metrics dataframe
metricDat <- metricDat %>% 
    mutate(lib_id = str_extract(lib_id, "lib[0-9]+"))

# Reformat variable names in design data frame
names(designDat) <- names(designDat) %>% 
    str_replace_all(" +", "_") %>% # replace spaces with underscores
    str_replace_all("#", "num") %>%  # replace # with 'num'
    str_replace_all("(\\(|\\))", "") %>% # remove parentheses
    str_to_lower() %>% # change to lower case
    str_replace("(?<=(lib))[a-z]+", "") %>% # replace 'library' with 'lib'
    make.unique(sep = "_") # de-dup variable names

# Remove empty rows from design data frame
designDat <- designDat %>% 
    filter(!is.na(lib_id))
    
```

```{r get_groups}
groupDat <- designDat %>% 
    mutate(koStatus = as.factor(tolower(str_extract(sample_name, "WT|BCAP"))),
           hscPop = as.factor(tolower(str_extract(hsc_population, 
                                                  "Long|Short")))) %>% 
    select(libID = lib_id,
           koStatus, hscPop)
```


#### Plot metrics

```{r summarize_metrics}
# Pull out and format the subset of metrics to plot; ; melt data frame for plotting
metricSummary <- metricDat %>% 
    mutate(percentDuplication = unpaired_read_duplicates / 
               unpaired_reads_examined) %>% 
    select(libID = lib_id, 
           medianCVcoverage = median_cv_coverage, 
           fastqTotalReads = fastq_total_reads, 
           percentAligned = mapped_reads_w_dups,
           percentDuplication)

```


```{r plot_metrics}
metricSummary %>% 
    plot_metric_qc("medianCVcoverage", 1)
metricSummary %>% 
    plot_metric_qc("percentAligned", 0.7)
```

#### Plot data

```{r}
# Filter genes with (cpm > 1) in < 5% of samples
dge = setUpDGEList(countData = countDat, 
                      filterCount = 1, 
                      filterPercentage = 0.05)

plotMDS(dge$counts, cex=.5, main="MDS, lib labeled",
        col = as.numeric(groupDat$koStatus)) # may have to kick out one individual
?plotMDS

```

