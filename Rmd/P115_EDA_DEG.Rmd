---
title: "P115-1 Analysis"
author: "James Eddy"
date: "July 31, 2015"
runtime: shiny
output: html_document
---

```{r global_opts}
knitr::opts_chunk$set(fig.width=8, fig.height=4, fig.align='center',
                      echo=FALSE, warning=FALSE, message=FALSE)
knitr::opts_knit$set(root.dir = "..")
```

### Set up R environment

#### Load packages

First, load required packages for data munging, visualization, and analysis
(these are largely Hadley Wickham libraries, plus some Bioconductor tools).

```{r load_packages}
# Load my go-to libraries
library(dplyr)
library(ggplot2)
library(ggthemes)
library(stringr)
library(readr)
library(readxl)
library(reshape2)

# ..plus some others I'll need here
library(edgeR)
library(limma)
```

Functions for plotting metrics are contained in `metric_qc_functions.R`.

```{r source_functions}
source("R/metric_qc_functions.R")
```

#### Define functions

These are functions written by Elizabeth Whalen (shared by Michael Mason) that
might come in handy with some steps of the analysis. I might rewrite these at
some point to better match my own coding style and/or needs. I'll also likely
move most functions to an external R script, which I can just source here.

```{r whalen_functions}
# Some functions from Elizabeth that I might use...

# computes normalization from libraries and then filters genes by having % 
# samples with at least N counts and 
setUpDGEList <- function(countData, filterCount = 1, filterPercentage = 0.1)
{
	d <- DGEList(counts = countData)
	d <- calcNormFactors(d)

	keepRows <- rowSums(round(cpm(d$counts)) >= filterCount) >= 
	    filterPercentage*ncol(countData)
	print(table(keepRows))

	curDGE <- d[keepRows, ]
	
	# reset library sizes
	# curDGE$samples$lib.size <- colSums(curDGE$counts)
	
	return(curDGE)
}
```

#### Load data

Next, load in counts and metrics data for the project, as well as sample
annotation for project libraries.
```{r load_data}
# Read CSV file with read counts
countFile <- "data/HMMF2ADXX_combined_counts_wMgiSymbol.csv"
countDat <- read_csv(countFile) # 37991 obs. of  18 variables
# str(countDat)

# Read CSV file with RNAseq/alignment metrics
metricFile <- "data/HMMF2ADXX_combined_metrics.csv"
metricDat <- read_csv(metricFile) # 16 obs. of  71 variables
# str(metricDat)

# Read XLSX file with sample annotation
designFile <- "data/JMD119 Sample Information .xlsx"
designDat <- read_excel(designFile, skip = 1) # 36 obs. of 18 variables
# str(designDat)
```


#### Clean data

I need to do a bit of cleaning/formatting with variable names (column headers)
to make life easier and avoid breaking downstream functions.
```{r clean_data}
gene <- countDat$mgiSymbol
countDat <- countDat %>% 
    select(-geneName, -mgiSymbol)
names(countDat) <- names(countDat) %>% 
    str_extract("lib[0-9]+")

# Reformat variable names in metrics data frame
names(metricDat) <- names(metricDat) %>% 
    str_to_lower() %>%  # change variable names to lower case
    make.unique(sep = "_") # de-dup variable names
names(metricDat)[1] <- "lib_id" # reformat libID variable name

# Reformat row names in metrics dataframe
metricDat <- metricDat %>% 
    mutate(lib_id = str_extract(lib_id, "lib[0-9]+"))

# Reformat variable names in design data frame
names(designDat) <- names(designDat) %>% 
    str_replace_all(" +", "_") %>% # replace spaces with underscores
    str_replace_all("#", "num") %>%  # replace # with 'num'
    str_replace_all("(\\(|\\))", "") %>% # remove parentheses
    str_to_lower() %>% # change to lower case
    str_replace("(?<=(lib))[a-z]+", "") %>% # replace 'library' with 'lib'
    make.unique(sep = "_") # de-dup variable names

# Remove empty rows from design data frame
designDat <- designDat %>% 
    filter(!is.na(lib_id))
    
```

```{r get_groups}
groupDat <- designDat %>% 
    mutate(koStatus = as.factor(tolower(str_extract(sample_name, "WT|BCAP"))),
           hscPop = as.factor(tolower(str_extract(hsc_population, 
                                                  "Long|Short"))),
           group = str_c(koStatus, hscPop, sep = "_")) %>% 
    select(libID = lib_id,
           koStatus, hscPop, group)
```


#### Plot metrics

```{r summarize_metrics}
# Pull out and format the subset of metrics to plot; ; melt data frame for plotting
metricSummary <- metricDat %>% 
    mutate(percentDuplication = unpaired_read_duplicates / 
               unpaired_reads_examined) %>% 
    select(libID = lib_id, 
           medianCVcoverage = median_cv_coverage, 
           fastqTotalReads = fastq_total_reads, 
           percentAligned = mapped_reads_w_dups,
           percentDuplication)

```

Adjust slider bars to set QC cutoffs (red lines) for x- and y-axis; dashed
lines indicate outlier limits (1.5*IQR).

##### Percent Aligned

```{r plot_perc_alingned_shiny}
sliderInput("alignCutoff", "percent aligned cutoff:", 
            min = 0, max = 1, step = 0.01,
            value = 0.8)
sliderInput("readsCutoff", "total FASTQ reads cutoff:", 
            min = 0, max = 5e7, step = 1e5,
            value = 1e6)

renderPlot({
    yRange <-c(input$alignCutoff, 1)
    xRange <- c(input$readsCutoff, max(metricSummary$fastqTotalReads) + 1e6)
    
    metricSummary %>%
        plot_metric("percentAligned", yRange, xRange)
})

```

##### Median CV Coverage

```{r plot_med_cv_cov_shiny}
sliderInput("covCutoff", "median CV coverage cutoff:", 
            min = 0, max = 3, step = 0.01,
            value = 1)
sliderInput("readsCutoff", "total FASTQ reads cutoff:", 
            min = 0, max = 5e7, step = 1e5,
            value = 1e6)

renderPlot({
    yRange <- c(0, input$covCutoff)
    xRange <- c(input$readsCutoff, max(metricSummary$fastqTotalReads) + 1e6)
    
    metricSummary %>%
        plot_metric("medianCVcoverage", yRange, xRange)
})

```

#### Examine data

```{r}
d1 <- DGEList(countDat)
d1 <- calcNormFactors(d1)
normFactorTest <- d1$samples %>% 
    add_rownames(var = "libID") %>% 
    mutate(test = "preFilter") %>% 
    select(-group)

filterCount <- 100
filterPercentage <- 0.2
d3 <- DGEList(countDat)
keepRows <- rowSums(round(cpm(d3$counts)) >= filterCount) >= 
    filterPercentage*ncol(countDat)
d3 <- d3[keepRows, ]
d3 <- calcNormFactors(d3)
normFactorTest <- d3$samples %>% 
    add_rownames(var = "libID") %>% 
    mutate(test = "postFilter") %>% 
    select(-group) %>% 
    bind_rows(normFactorTest, .)

d5 <- DGEList(countDat)
keepRows <- rowSums(round(cpm(d5$counts)) >= filterCount) >= 
    filterPercentage*ncol(countDat)
d5 <- d5[keepRows, ]
d5$samples$lib.size <- colSums(d5$counts)
d5 <- calcNormFactors(d5)
normFactorTest <- d5$samples %>% 
    add_rownames(var = "libID") %>% 
    mutate(test = "postFilter_corrected") %>% 
    select(-group) %>% 
    bind_rows(normFactorTest, .)

normFactorTest %>% 
    mutate(test = relevel(as.factor(test), "preFilter")) %>% 
    ggplot(aes(x = libID, y = norm.factors)) +
    geom_bar(aes(fill = test), stat = "identity", 
               colour = "white",
               position = "dodge") +
    scale_fill_colorblind()
```

```{r}
# Filter genes with (cpm > 1) in < 5% of samples
dge = setUpDGEList(countData = countDat, 
                      filterCount = 100, 
                      filterPercentage = 0.20)

dim(dge)
head(dge$counts)
head(cpm(dge))
apply(dge$counts, 2, sum)
str(dge)
```


#### Plot data

```{r}


# pca <- prcomp(dge$counts)
# pcaDat <- data.frame(groupDat, pca$x[, 1:3])
# plotMDS(dge$counts, cex=.5, main="MDS, lib labeled",
#         col = as.numeric(groupDat$koStatus)) # may have to kick out one individual
# ?plotMDS

```

